{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of MMA 2022W 869 Individual Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKmorPdno_n_"
      },
      "source": [
        "# MMA 869: Individual Assignment\n",
        "\n",
        "<font color='red'>\\# TODO: fill in the below</font>\n",
        "\n",
        "- [Adaure, Ibe]\n",
        "- [20254264]\n",
        "- [Section 2]\n",
        "- [The Road Less Traveled]\n",
        "- [1-8-2021]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emfFtv4aHBI1"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "This assignment contains four questions. The questions are fully contained in this Google Colab Notebook. \n",
        "\n",
        "You are to make a copy of this Notebook and edit the copy to provide your answers. You are to complete the assignment entirely within Google Colab. Why?\n",
        "\n",
        "- It gives you practice using cloud-based interactive notebook environments (which is a popular workflow)\n",
        "- It is easier for you to manage the environment (e.g., installing packages, etc.)\n",
        "- Google Colab has nice, beefy machines, so you don't have to worry about running out of memory on your local computer.\n",
        "- It will be easier for the TA to help you debug your code if you need help\n",
        "- It will be easier for the TA to mark/run your code\n",
        "\n",
        "Some parts of this assigment require you to write code. Use Python. You may use standard Python libraries, including `scikit-learn`, `pandas`, `numpy`, and scipy`.\n",
        "\n",
        "Some parts of this assignment require text responses. In these cases, type your response in the Notebook cell indicated. Use English. Use proper grammar, spelling, and punctuation. Be professional and clear. Be complete, but not overly-verbose. Feel free to use [Markdown syntax](https://www.markdownguide.org/basic-syntax/) to format your answer (i.e., add bold, italics, lists, tables).\n",
        "\n",
        "## What to Submit to the Course Portal\n",
        "\n",
        "- Export your completed Notebook as a PDF file by clicking File->Print->Save as PDF.\n",
        "- Please do not submit the Notebook file (`.ipynb`) to the course portal. \n",
        "- Please submit the PDF export of the Notebook. \n",
        "   - Please name the PDF file `2022_869_FirstnameLastName.pdf`\n",
        "      - E.g., `2022_869_StephenThomas.pdf`\n",
        "   - Please make sure you have run all the cells so we can see the output!\n",
        "   - Best practice: Before exporting to PDF click Runtime->Restart and run all.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZFTCX4DqmRO"
      },
      "source": [
        "# Preliminaries: Inspect and Set up environment\n",
        "\n",
        "No action is required on your part in this section. These cells print out helpful information about the environment, just in case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj34Jz-Do_oK"
      },
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqQ_XOKyXTS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779183c1-0ae9-4589-98bf-9ec3db98a4e9"
      },
      "source": [
        "print(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-15 22:31:44.071052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfOMt1lErLhZ",
        "outputId": "db48ea46-b59d-4b57-f368-bc82f93bab6f"
      },
      "source": [
        "!which python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aub2w1-arM5K",
        "outputId": "e76d846d-2a49-4e7a-bd47-f39bd3231d6c"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Y_n_8UrO9i",
        "outputId": "89c98bcb-5919-4df1-f8a4-9cc29af1f354"
      },
      "source": [
        "!echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHUVO0Dit0Xk",
        "outputId": "e05f0a7b-6a1e-4e1e-de5c-64aa8a5f7278"
      },
      "source": [
        "# TODO: install any packages you need to here. For example\n",
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qyD7Jl0Gw1E"
      },
      "source": [
        "#Importing packages to be used in project\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Importing clustering packages\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLlBjIyS2o54"
      },
      "source": [
        "# Question 1: Uncle Steve's Diamonds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj1NSQelo_oN"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "You work at a local jewelry store named *Uncle Steve's Diamonds*. You started as a janitor, but you’ve recently been promoted to senior data analyst! Congratulations.\n",
        "\n",
        "Uncle Steve, the store's owner, needs to better understand the store's customers. In particular, he wants to know what kind of customers shop at the store. He wants to know the main types of *customer personas*. Once he knows these, he will contemplate ways to better market to each persona, better satisfy each persona, better cater to each persona, increase the loyalty of each persona, etc. But first, he must know the personas.\n",
        "\n",
        "You want to help Uncle Steve. Using sneaky magic (and the help of Environics), you've collected four useful features for a subset of the customers: age, income, spending score (i.e., a score based on how much they’ve spent at the store in total), and savings (i.e., how much money they have in their personal bank account). \n",
        "\n",
        "**Your tasks**\n",
        "\n",
        "1. Pick a clustering algorithm (the [`sklearn.cluster`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster) module has many good choices, including [`KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans), [`DBSCAN`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN), and [`AgglomerativeClustering`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering) (aka Hierarchical). (Note that another popular implementation of the hierarchical algorithm can be found in SciPy's [`scipy.cluster.hierarchy.linkage`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html).) Don't spend a lot of time thinking about which algorithm to choose - just pick one. Cluster the customers as best as you can, within reason. That is, try different feature preprocessing steps, hyperparameter values, and/or distance metrics. You don't need to try every single posssible combination, but try a few at least. Measure how good each  model configuration is by calculating an internal validation metric (e.g., [`calinski_harabasz_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html) or [`silhouette_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score)).\n",
        "2. You have some doubts - you're not sure if the algorithm you chose in part 1 is the best algorithm for this dataset/problem. Neither is Uncle Steve. So, choose a different algorithm (any!) and do it all again.\n",
        "3. Which clustering algorithm is \"better\" in this case? Think about charateristics of the algorithm like quality of results, ease of use, speed, interpretability, etc. Choose a winner and justify to Uncle Steve.\n",
        "4. Interpret the clusters of the winning model. That is, describe, in words, a *persona* that accurately depicts each cluster. Use statistics (e.g., cluster means/distributions), examples (e.g., exemplar instances from each cluster), and/or visualizations (e.g., relative importance plots, snakeplots) to get started. Human judgement and creativity will be necessary. This is where it all comes together. Be descripive and *help Uncle Steve understand his customers better*. Please!\n",
        "\n",
        "**Marking**\n",
        "\n",
        "The coding parts (i.e., 1 and 2) will be marked based on:\n",
        "\n",
        "- *Correctness*. Code clearly and fully performs the task specified.\n",
        "- *Reproducibility*. Code is fully reproducible. I.e., you (and I) are able to run this Notebook again and again, from top to bottom, and get the same results each time.\n",
        "- *Style*. Code is organized. All parts commented with clear reasoning and rationale. No old code laying around. Code easy to follow.\n",
        "\n",
        "\n",
        "Parts 3 and 4 will be marked on:\n",
        "\n",
        "- *Quality*. Response is well-justified and convincing. Responses uses facts and data where possible.\n",
        "- *Style*. Response uses proper grammar, spelling, and punctuation. Response is clear and professional. Response is complete, but not overly-verbose. Response follows length guidelines.\n",
        "\n",
        "\n",
        "**Tips**\n",
        "\n",
        "- Since clustering is an unsupervised ML technique, you don't need to split the data into training/validation/test or anything like that. Phew!\n",
        "- On the flip side, since clustering is unsupervised, you will never know the \"true\" clusters, and so you will never know if a given algorithm is \"correct.\" There really is no notion of \"correctness\" - only \"usefullness.\"\n",
        "- Many online clustering tutorials (including some from Uncle Steve) create flashy visualizations of the clusters by plotting the instances on a 2-D graph and coloring each point by the cluster ID. This is really nice and all, but it can only work if your dataset only has exactly two features - no more, no less. This dataset has more than two features, so you cannot use this technique. (But that's OK - you don't need to use this technique.) \n",
        "- Must you use all four features in the clustering? Not necessarily, no. But \"throwing away\" quality data, for no reason, is unlikely to improve a model.\n",
        "- Some people have success applying a dimensionality reduction technique (like [`sklearn.decomposition.PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)) to the features before clustering. You may do this if you wish, although it may not be as helpful in this case because there are only four features to begin with.\n",
        "- If you apply a transformation (e.g., [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) or [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)) to the features before clustering, you may have difficulty interpretting the means of the clusters (e.g., what is a mean Age of 0.2234??). There are two options to fix this: first, you can always reverse a transformation with the `inverse_transform` method. Second, you can just use the original dataset (i.e., before any prepropoceesing) during the interpreation step.\n",
        "- You cannot change the distance metric for K-Means. (This is for theoretical reasons: K-Means only works/makes sense with Euclidean distance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yww0-vtpOw7z"
      },
      "source": [
        "## 1.0: Load data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVWx2c-DhQYo",
        "outputId": "b86b9ba8-01ca-4325-f373-a220f70a2211"
      },
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "df1 = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1thHDCwQK3GijytoSSZNekAsItN_FGHtm\") #This DF will be standarzided  \n",
        "df1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 505 entries, 0 to 504\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Age            505 non-null    int64  \n",
            " 1   Income         505 non-null    int64  \n",
            " 2   SpendingScore  505 non-null    float64\n",
            " 3   Savings        505 non-null    float64\n",
            "dtypes: float64(2), int64(2)\n",
            "memory usage: 15.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP4eVJXABLAd"
      },
      "source": [
        "df2 = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1thHDCwQK3GijytoSSZNekAsItN_FGHtm\") #This DF will be normalized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqX2BIS6aRYG"
      },
      "source": [
        "df5 = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1thHDCwQK3GijytoSSZNekAsItN_FGHtm\") #This DF will be used in the interpretation of clusters "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ky2QmQvmNV1j",
        "outputId": "3c497d9f-29b6-4b9c-87e9-57161df27f3e"
      },
      "source": [
        "#Data Exploration\n",
        "list(df1)\n",
        "df1.shape\n",
        "df1.info()\n",
        "df1.describe().transpose()\n",
        "df1.head(n=20)\n",
        "df1.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Age', 'Income', 'SpendingScore', 'Savings']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(505, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 505 entries, 0 to 504\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Age            505 non-null    int64  \n",
            " 1   Income         505 non-null    int64  \n",
            " 2   SpendingScore  505 non-null    float64\n",
            " 3   Savings        505 non-null    float64\n",
            "dtypes: float64(2), int64(2)\n",
            "memory usage: 15.9 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>505.0</td>\n",
              "      <td>59.019802</td>\n",
              "      <td>24.140043</td>\n",
              "      <td>17.0</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>97.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Income</th>\n",
              "      <td>505.0</td>\n",
              "      <td>75513.291089</td>\n",
              "      <td>35992.922184</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>34529.000000</td>\n",
              "      <td>75078.000000</td>\n",
              "      <td>107100.000000</td>\n",
              "      <td>142000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SpendingScore</th>\n",
              "      <td>505.0</td>\n",
              "      <td>0.505083</td>\n",
              "      <td>0.259634</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.304792</td>\n",
              "      <td>0.368215</td>\n",
              "      <td>0.768279</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Savings</th>\n",
              "      <td>505.0</td>\n",
              "      <td>11862.455867</td>\n",
              "      <td>4949.229253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6828.709702</td>\n",
              "      <td>14209.932802</td>\n",
              "      <td>16047.268331</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               count          mean  ...            75%       max\n",
              "Age            505.0     59.019802  ...      85.000000      97.0\n",
              "Income         505.0  75513.291089  ...  107100.000000  142000.0\n",
              "SpendingScore  505.0      0.505083  ...       0.768279       1.0\n",
              "Savings        505.0  11862.455867  ...   16047.268331   20000.0\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Income</th>\n",
              "      <th>SpendingScore</th>\n",
              "      <th>Savings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>77769</td>\n",
              "      <td>0.791329</td>\n",
              "      <td>6559.829923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59</td>\n",
              "      <td>81799</td>\n",
              "      <td>0.791082</td>\n",
              "      <td>5417.661426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "      <td>74751</td>\n",
              "      <td>0.702657</td>\n",
              "      <td>9258.992965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59</td>\n",
              "      <td>74373</td>\n",
              "      <td>0.765680</td>\n",
              "      <td>7346.334504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>87</td>\n",
              "      <td>17760</td>\n",
              "      <td>0.348778</td>\n",
              "      <td>16869.507130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>29</td>\n",
              "      <td>131578</td>\n",
              "      <td>0.847034</td>\n",
              "      <td>3535.514352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>54</td>\n",
              "      <td>76500</td>\n",
              "      <td>0.785198</td>\n",
              "      <td>6878.884249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>87</td>\n",
              "      <td>42592</td>\n",
              "      <td>0.355290</td>\n",
              "      <td>18086.287158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>83</td>\n",
              "      <td>34384</td>\n",
              "      <td>0.324719</td>\n",
              "      <td>14783.379086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>84</td>\n",
              "      <td>27693</td>\n",
              "      <td>0.367063</td>\n",
              "      <td>17879.558906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>85</td>\n",
              "      <td>111389</td>\n",
              "      <td>0.036795</td>\n",
              "      <td>16009.237763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>36</td>\n",
              "      <td>99780</td>\n",
              "      <td>0.265433</td>\n",
              "      <td>16398.401333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>30</td>\n",
              "      <td>99949</td>\n",
              "      <td>0.344679</td>\n",
              "      <td>13621.639726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>31</td>\n",
              "      <td>107963</td>\n",
              "      <td>0.290509</td>\n",
              "      <td>13407.081391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>61</td>\n",
              "      <td>71933</td>\n",
              "      <td>0.844107</td>\n",
              "      <td>8022.208541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>92</td>\n",
              "      <td>122879</td>\n",
              "      <td>0.060724</td>\n",
              "      <td>13709.670275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>55</td>\n",
              "      <td>71621</td>\n",
              "      <td>0.753343</td>\n",
              "      <td>7780.589914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>87</td>\n",
              "      <td>31481</td>\n",
              "      <td>0.317424</td>\n",
              "      <td>16180.688082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>82</td>\n",
              "      <td>33636</td>\n",
              "      <td>0.371783</td>\n",
              "      <td>17866.833598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>88</td>\n",
              "      <td>120678</td>\n",
              "      <td>0.063273</td>\n",
              "      <td>14264.473847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  Income  SpendingScore       Savings\n",
              "0    58   77769       0.791329   6559.829923\n",
              "1    59   81799       0.791082   5417.661426\n",
              "2    62   74751       0.702657   9258.992965\n",
              "3    59   74373       0.765680   7346.334504\n",
              "4    87   17760       0.348778  16869.507130\n",
              "5    29  131578       0.847034   3535.514352\n",
              "6    54   76500       0.785198   6878.884249\n",
              "7    87   42592       0.355290  18086.287158\n",
              "8    83   34384       0.324719  14783.379086\n",
              "9    84   27693       0.367063  17879.558906\n",
              "10   85  111389       0.036795  16009.237763\n",
              "11   36   99780       0.265433  16398.401333\n",
              "12   30   99949       0.344679  13621.639726\n",
              "13   31  107963       0.290509  13407.081391\n",
              "14   61   71933       0.844107   8022.208541\n",
              "15   92  122879       0.060724  13709.670275\n",
              "16   55   71621       0.753343   7780.589914\n",
              "17   87   31481       0.317424  16180.688082\n",
              "18   82   33636       0.371783  17866.833598\n",
              "19   88  120678       0.063273  14264.473847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Income</th>\n",
              "      <th>SpendingScore</th>\n",
              "      <th>Savings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>28</td>\n",
              "      <td>101206</td>\n",
              "      <td>0.387441</td>\n",
              "      <td>14936.775389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>93</td>\n",
              "      <td>19934</td>\n",
              "      <td>0.203140</td>\n",
              "      <td>17969.693769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>90</td>\n",
              "      <td>35297</td>\n",
              "      <td>0.355149</td>\n",
              "      <td>16091.401954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>91</td>\n",
              "      <td>20681</td>\n",
              "      <td>0.354679</td>\n",
              "      <td>18401.088445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>89</td>\n",
              "      <td>30267</td>\n",
              "      <td>0.289310</td>\n",
              "      <td>14386.351880</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Income  SpendingScore       Savings\n",
              "500   28  101206       0.387441  14936.775389\n",
              "501   93   19934       0.203140  17969.693769\n",
              "502   90   35297       0.355149  16091.401954\n",
              "503   91   20681       0.354679  18401.088445\n",
              "504   89   30267       0.289310  14386.351880"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP4AgWTWOqgS"
      },
      "source": [
        "#scaling the data\n",
        "scaler = StandardScaler()\n",
        "features = ['Age', 'SpendingScore','Income','Savings']\n",
        "df1[features] = scaler.fit_transform(df1[features])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "Xv2oYSfoOqi7",
        "outputId": "931368e4-9138-4f5e-ef75-0f4b58f39354"
      },
      "source": [
        "#Reviewing standardized data\n",
        "df1.shape\n",
        "df1.info()\n",
        "df1.describe().transpose()\n",
        "df1.head(10)\n",
        "df1.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(505, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 505 entries, 0 to 504\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Age            505 non-null    float64\n",
            " 1   Income         505 non-null    float64\n",
            " 2   SpendingScore  505 non-null    float64\n",
            " 3   Savings        505 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 15.9 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>505.0</td>\n",
              "      <td>5.672031e-17</td>\n",
              "      <td>1.000992</td>\n",
              "      <td>-1.742394</td>\n",
              "      <td>-1.037472</td>\n",
              "      <td>-0.000821</td>\n",
              "      <td>1.077295</td>\n",
              "      <td>1.574888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Income</th>\n",
              "      <td>505.0</td>\n",
              "      <td>-2.638154e-17</td>\n",
              "      <td>1.000992</td>\n",
              "      <td>-1.766355</td>\n",
              "      <td>-1.139805</td>\n",
              "      <td>-0.012106</td>\n",
              "      <td>0.878451</td>\n",
              "      <td>1.849048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SpendingScore</th>\n",
              "      <td>505.0</td>\n",
              "      <td>-1.954432e-16</td>\n",
              "      <td>1.000992</td>\n",
              "      <td>-1.947295</td>\n",
              "      <td>-0.772201</td>\n",
              "      <td>-0.527678</td>\n",
              "      <td>1.014725</td>\n",
              "      <td>1.908103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Savings</th>\n",
              "      <td>505.0</td>\n",
              "      <td>-4.058360e-16</td>\n",
              "      <td>1.000992</td>\n",
              "      <td>-2.399206</td>\n",
              "      <td>-1.018085</td>\n",
              "      <td>0.474782</td>\n",
              "      <td>0.846387</td>\n",
              "      <td>1.645835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               count          mean       std  ...       50%       75%       max\n",
              "Age            505.0  5.672031e-17  1.000992  ... -0.000821  1.077295  1.574888\n",
              "Income         505.0 -2.638154e-17  1.000992  ... -0.012106  0.878451  1.849048\n",
              "SpendingScore  505.0 -1.954432e-16  1.000992  ... -0.527678  1.014725  1.908103\n",
              "Savings        505.0 -4.058360e-16  1.000992  ...  0.474782  0.846387  1.645835\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Income</th>\n",
              "      <th>SpendingScore</th>\n",
              "      <th>Savings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.042287</td>\n",
              "      <td>0.062733</td>\n",
              "      <td>1.103593</td>\n",
              "      <td>-1.072467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.000821</td>\n",
              "      <td>0.174811</td>\n",
              "      <td>1.102641</td>\n",
              "      <td>-1.303473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.123577</td>\n",
              "      <td>-0.021200</td>\n",
              "      <td>0.761727</td>\n",
              "      <td>-0.526556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.000821</td>\n",
              "      <td>-0.031712</td>\n",
              "      <td>1.004705</td>\n",
              "      <td>-0.913395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.160228</td>\n",
              "      <td>-1.606165</td>\n",
              "      <td>-0.602619</td>\n",
              "      <td>1.012686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-1.244802</td>\n",
              "      <td>1.559204</td>\n",
              "      <td>1.318359</td>\n",
              "      <td>-1.684141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.208151</td>\n",
              "      <td>0.027441</td>\n",
              "      <td>1.079955</td>\n",
              "      <td>-1.007937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.160228</td>\n",
              "      <td>-0.915567</td>\n",
              "      <td>-0.577512</td>\n",
              "      <td>1.258782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.994363</td>\n",
              "      <td>-1.143838</td>\n",
              "      <td>-0.695375</td>\n",
              "      <td>0.590763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.035829</td>\n",
              "      <td>-1.329920</td>\n",
              "      <td>-0.532121</td>\n",
              "      <td>1.216971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Age    Income  SpendingScore   Savings\n",
              "0 -0.042287  0.062733       1.103593 -1.072467\n",
              "1 -0.000821  0.174811       1.102641 -1.303473\n",
              "2  0.123577 -0.021200       0.761727 -0.526556\n",
              "3 -0.000821 -0.031712       1.004705 -0.913395\n",
              "4  1.160228 -1.606165      -0.602619  1.012686\n",
              "5 -1.244802  1.559204       1.318359 -1.684141\n",
              "6 -0.208151  0.027441       1.079955 -1.007937\n",
              "7  1.160228 -0.915567      -0.577512  1.258782\n",
              "8  0.994363 -1.143838      -0.695375  0.590763\n",
              "9  1.035829 -1.329920      -0.532121  1.216971"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Income</th>\n",
              "      <th>SpendingScore</th>\n",
              "      <th>Savings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>-1.286268</td>\n",
              "      <td>0.714535</td>\n",
              "      <td>-0.453557</td>\n",
              "      <td>0.621787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>1.409024</td>\n",
              "      <td>-1.545704</td>\n",
              "      <td>-1.164109</td>\n",
              "      <td>1.235201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>1.284626</td>\n",
              "      <td>-1.118447</td>\n",
              "      <td>-0.578054</td>\n",
              "      <td>0.855313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>1.326092</td>\n",
              "      <td>-1.524929</td>\n",
              "      <td>-0.579866</td>\n",
              "      <td>1.322452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>1.243160</td>\n",
              "      <td>-1.258335</td>\n",
              "      <td>-0.831890</td>\n",
              "      <td>0.510463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Age    Income  SpendingScore   Savings\n",
              "500 -1.286268  0.714535      -0.453557  0.621787\n",
              "501  1.409024 -1.545704      -1.164109  1.235201\n",
              "502  1.284626 -1.118447      -0.578054  0.855313\n",
              "503  1.326092 -1.524929      -0.579866  1.322452\n",
              "504  1.243160 -1.258335      -0.831890  0.510463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R04NzckZKbG2"
      },
      "source": [
        "## 1.1: Clustering Algorithm #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnWrWp5y44QQ"
      },
      "source": [
        "##### K Means Cluster 1, K = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qeavkicwo_oN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e80aba-9fba-48fc-a3fb-154894da730c"
      },
      "source": [
        "k_means = KMeans(n_clusters=3, random_state=42)\n",
        "k_means.fit(df1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=42, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ogxYGOUtgfL",
        "outputId": "244afe9a-bd20-4ce6-f497-fda8493a5d19"
      },
      "source": [
        "k_means.labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 2, 2, 2, 1, 2, 1, 0, 0, 2, 2, 2,\n",
              "       1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 0, 1, 2, 2, 1, 0, 1, 1,\n",
              "       1, 1, 2, 1, 2, 1, 0, 2, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 0, 2, 2, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 0, 0, 2, 2, 1,\n",
              "       0, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 0, 0, 2, 2, 1, 0, 1, 1, 2, 1,\n",
              "       2, 1, 1, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0, 1,\n",
              "       0, 2, 2, 1, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 1, 2, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 2, 1, 1, 0, 2, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 2,\n",
              "       0, 0, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 2, 1, 2, 0,\n",
              "       1, 1, 2, 0, 2, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1,\n",
              "       1, 1, 2, 1, 2, 0, 1, 1, 1, 0, 1, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 0,\n",
              "       1, 0, 2, 1, 1, 2, 0, 1, 0, 0, 2, 1, 0, 0, 1, 1, 0, 2, 2, 2, 2, 0,\n",
              "       0, 2, 2, 0, 0, 1, 1, 2, 2, 1, 2, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 0,\n",
              "       2, 2, 0, 2, 2, 1, 0, 2, 1, 1, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1,\n",
              "       2, 1, 1, 2, 2, 0, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 1, 0, 0, 2, 2, 2,\n",
              "       2, 2, 1, 2, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 2, 2, 1, 0, 0,\n",
              "       0, 0, 0, 2, 2, 0, 1, 2, 1, 2, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 1, 2,\n",
              "       1, 2, 1, 0, 2, 1, 1, 1, 0, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2,\n",
              "       0, 1, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 2, 1, 1, 2, 1, 0, 1, 2, 1, 0,\n",
              "       1, 0, 1, 2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 2,\n",
              "       1, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0, 2, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 2, 1, 2, 0, 0, 0, 0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qINgALruL0Q",
        "outputId": "d5110baa-26cf-4683-d09e-e647bf4196d8"
      },
      "source": [
        "#Reviewing the centre of the cluster\n",
        "k_means.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.19238486, -1.32510593, -0.67963841,  0.97016358],\n",
              "       [-0.31952856,  0.28812391,  1.14397016, -1.14260341],\n",
              "       [-0.72276928,  0.89502598, -0.90658925,  0.62188649]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bjBT5ONuf8n",
        "outputId": "382b0434-297f-4984-ea5b-bc0a6bdecf66"
      },
      "source": [
        "silhouette_score(df1, k_means.labels_) #assesing K means model 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6963481945884472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd4iOkQoBfco"
      },
      "source": [
        "###### K Means Cluster 2, K = 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX9fTawvtgvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fe5842-4f51-4390-eddf-ab1294741dc1"
      },
      "source": [
        "k_means = KMeans(n_clusters=5, random_state=42)\n",
        "k_means.fit(df1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=42, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRJkZowd5oif",
        "outputId": "fee94983-c5cd-4795-af89-4540012dae3a"
      },
      "source": [
        "#Reviewing the centre of the cluster\n",
        "k_means.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.19238486, -1.32510593, -0.67963841,  0.97016358],\n",
              "       [-1.08815238,  0.82744102, -0.75240648,  0.6270464 ],\n",
              "       [ 0.03879611, -0.08524639,  1.02721559, -1.00569483],\n",
              "       [-1.44466803,  1.46050665,  1.51057952, -1.57249636],\n",
              "       [ 1.11876151,  1.23565419, -1.68367042,  0.59588052]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHbRw5CT6SUF",
        "outputId": "3b2f7d75-167b-44ad-ee36-ab2ba11e59c5"
      },
      "source": [
        "silhouette_score(df1, k_means.labels_) #assesing k means model 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8048976287755765"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5BklQuGc1Wi"
      },
      "source": [
        "###### K Means Cluster 3, K = 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpNRGEDL6SiQ",
        "outputId": "1489f0b7-3805-43ee-91fe-62ce3f14845d"
      },
      "source": [
        "k_means = KMeans(n_clusters=7, random_state=42)\n",
        "k_means.fit(df1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=42, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGckqCCu5zPJ",
        "outputId": "ebd1c2da-f3b2-485e-9f91-ba8a4a7fc6f9"
      },
      "source": [
        "#Reviewing the centre of the cluster\n",
        "k_means.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.08815238,  0.82744102, -0.75240648,  0.6270464 ],\n",
              "       [ 0.07457166, -0.04739431,  1.103503  , -1.17579009],\n",
              "       [ 1.20769522, -1.32463708, -0.66366435,  1.15332719],\n",
              "       [-1.44466803,  1.46050665,  1.51057952, -1.57249636],\n",
              "       [ 1.11876151,  1.23565419, -1.68367042,  0.59588052],\n",
              "       [ 0.01284901, -0.11269955,  0.97188625, -0.88232903],\n",
              "       [ 1.1759963 , -1.3256078 , -0.6967374 ,  0.77410112]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_792eUTT66uq",
        "outputId": "94345faa-e944-441c-d33a-f9e3091a33d3"
      },
      "source": [
        "silhouette_score(df1, k_means.labels_) #assesing k means model 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44624135722251396"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "v4fUyzbe8KYq",
        "outputId": "55733700-535b-4552-ca47-3fa2de4b4f4a"
      },
      "source": [
        "#selecting the optimal hyperparameters\n",
        "inertias = {}\n",
        "silhouettes = {}\n",
        "for k in range(2, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42).fit(df1)\n",
        "    inertias[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
        "    silhouettes[k] = silhouette_score(df1, kmeans.labels_, metric='euclidean')\n",
        "    \n",
        "\n",
        "plt.figure();\n",
        "plt.plot(list(inertias.keys()), list(inertias.values()));\n",
        "plt.title('K-Means, Elbow Method')\n",
        "plt.xlabel(\"Number of clusters, K\");\n",
        "plt.ylabel(\"Inertia\");\n",
        "\n",
        "\n",
        "plt.figure();\n",
        "plt.plot(list(silhouettes.keys()), list(silhouettes.values()));\n",
        "plt.title('K-Means, Elbow Method')\n",
        "plt.xlabel(\"Number of clusters, K\");\n",
        "plt.ylabel(\"Silhouette\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D02dmBI8Zy5"
      },
      "source": [
        "##### The Ideal Number of clusters is **5** in both the inertia and silhouette plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVtYBWg1NM6"
      },
      "source": [
        "## 1.2: Clustering Algorithm #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9p6j13VgY2s"
      },
      "source": [
        "#Normalizing the data\n",
        "from sklearn import preprocessing\n",
        "x = df2.values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "df2 = pd.DataFrame(x_scaled)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WEKSbwyIhBXX",
        "outputId": "75173fa0-02d5-4033-9c7c-19c83931a846"
      },
      "source": [
        "df2.head(5) #review transfromed data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.505915</td>\n",
              "      <td>0.791329</td>\n",
              "      <td>0.327991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.536915</td>\n",
              "      <td>0.791082</td>\n",
              "      <td>0.270883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.482700</td>\n",
              "      <td>0.702657</td>\n",
              "      <td>0.462950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5250</td>\n",
              "      <td>0.479792</td>\n",
              "      <td>0.765680</td>\n",
              "      <td>0.367317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.044308</td>\n",
              "      <td>0.348778</td>\n",
              "      <td>0.843475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3\n",
              "0  0.5125  0.505915  0.791329  0.327991\n",
              "1  0.5250  0.536915  0.791082  0.270883\n",
              "2  0.5625  0.482700  0.702657  0.462950\n",
              "3  0.5250  0.479792  0.765680  0.367317\n",
              "4  0.8750  0.044308  0.348778  0.843475"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR5d-IJZDIIN",
        "outputId": "6e4c0557-3c16-4b1c-9867-4d0b62760376"
      },
      "source": [
        "#DBSCAN Model 1\n",
        "db = DBSCAN(eps=0.3, min_samples=3, leaf_size=30, metric='euclidean')\n",
        "db.fit(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(algorithm='auto', eps=0.3, leaf_size=30, metric='euclidean',\n",
              "       metric_params=None, min_samples=3, n_jobs=None, p=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiLpl4YbmAei",
        "outputId": "d46c3a63-35b9-42a4-f8d0-e9e6c05aa042"
      },
      "source": [
        "db.labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 2, 0, 1, 1, 1, 3, 4, 4, 4, 0, 3, 0, 1, 1, 3, 4, 3,\n",
              "       0, 1, 3, 2, 2, 0, 1, 0, 0, 0, 1, 0, 4, 0, 1, 0, 4, 4, 0, 1, 2, 0,\n",
              "       0, 2, 3, 2, 4, 0, 1, 4, 2, 1, 0, 1, 4, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 2, 2, 0, 0, 4, 1, 1, 4, 0, 4, 0, 0, 2, 0, 3, 0, 1, 1, 4, 4, 0,\n",
              "       0, 0, 0, 0, 2, 1, 0, 2, 4, 0, 0, 4, 4, 2, 4, 2, 4, 1, 1, 4, 4, 0,\n",
              "       1, 4, 0, 4, 4, 4, 0, 4, 2, 1, 4, 1, 1, 1, 4, 3, 0, 1, 0, 0, 4, 0,\n",
              "       4, 0, 2, 1, 3, 2, 0, 4, 1, 0, 0, 2, 0, 2, 0, 3, 0, 1, 0, 4, 1, 0,\n",
              "       1, 3, 4, 0, 1, 0, 4, 1, 0, 4, 1, 4, 1, 0, 4, 0, 1, 0, 4, 0, 1, 0,\n",
              "       0, 1, 1, 1, 0, 0, 4, 2, 2, 1, 4, 0, 0, 0, 4, 1, 0, 0, 0, 1, 2, 4,\n",
              "       1, 1, 1, 4, 0, 4, 0, 4, 0, 1, 2, 0, 1, 1, 1, 1, 0, 1, 4, 2, 4, 1,\n",
              "       0, 0, 4, 1, 4, 2, 4, 0, 0, 1, 0, 0, 1, 0, 0, 0, 4, 0, 4, 4, 2, 0,\n",
              "       0, 0, 3, 0, 4, 1, 2, 2, 2, 1, 0, 4, 1, 1, 4, 4, 0, 0, 3, 0, 0, 1,\n",
              "       0, 1, 4, 2, 0, 4, 1, 0, 1, 1, 4, 0, 1, 1, 0, 0, 1, 4, 4, 3, 4, 1,\n",
              "       1, 4, 3, 1, 1, 2, 0, 4, 4, 0, 4, 1, 1, 4, 0, 4, 1, 0, 4, 2, 0, 1,\n",
              "       4, 4, 1, 3, 3, 0, 1, 4, 0, 0, 1, 4, 1, 4, 1, 4, 1, 1, 4, 1, 4, 0,\n",
              "       4, 0, 0, 4, 4, 1, 1, 2, 2, 4, 1, 2, 1, 3, 0, 0, 0, 1, 1, 4, 4, 3,\n",
              "       4, 3, 0, 4, 2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 4, 0, 3, 4, 4, 0, 1, 1,\n",
              "       1, 1, 1, 4, 4, 1, 0, 4, 0, 3, 1, 1, 0, 1, 1, 0, 1, 1, 4, 1, 0, 4,\n",
              "       2, 4, 0, 1, 4, 0, 0, 0, 1, 4, 2, 4, 0, 4, 0, 0, 2, 4, 3, 2, 4, 4,\n",
              "       1, 0, 1, 4, 1, 4, 0, 0, 1, 3, 4, 1, 4, 0, 0, 4, 0, 1, 0, 4, 0, 1,\n",
              "       0, 1, 2, 4, 4, 2, 4, 4, 1, 1, 0, 2, 0, 4, 4, 3, 2, 4, 2, 1, 4, 4,\n",
              "       0, 4, 1, 1, 2, 0, 4, 0, 0, 4, 0, 0, 0, 1, 4, 4, 0, 0, 0, 1, 4, 1,\n",
              "       1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 4, 2, 4, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN-AYIMwDIgZ",
        "outputId": "d77f4b94-b73b-447d-fe18-fe3f0e5a4bdb"
      },
      "source": [
        "silhouette_score(df2, db.labels_) #assesing model results\n",
        "db.fit(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8156911152768872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(algorithm='auto', eps=0.3, leaf_size=30, metric='euclidean',\n",
              "       metric_params=None, min_samples=3, n_jobs=None, p=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpFesZIDFz0W",
        "outputId": "661bc61b-ae0c-4e62-92d9-06de3cbc8274"
      },
      "source": [
        "#DB Scan Model 2\n",
        "db2 = DBSCAN(eps=0.5, min_samples=4)\n",
        "db2.fit(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(algorithm='auto', eps=0.5, leaf_size=30, metric='euclidean',\n",
              "       metric_params=None, min_samples=4, n_jobs=None, p=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we_VIftGF09k",
        "outputId": "63a3c311-c33e-4b6c-bbef-004729aae0a9"
      },
      "source": [
        "silhouette_score(df2, db.labels_) #assesing Model Results\n",
        "db2.fit(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8156911152768872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(algorithm='auto', eps=0.5, leaf_size=30, metric='euclidean',\n",
              "       metric_params=None, min_samples=4, n_jobs=None, p=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mChanpDVF1AF",
        "outputId": "81dbb76b-c528-449b-a5fe-2a72fe24c9f5"
      },
      "source": [
        "#DB San Model 3\n",
        "db3 = DBSCAN(eps=0.1, min_samples=5)\n",
        "db3.fit(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(algorithm='auto', eps=0.1, leaf_size=30, metric='euclidean',\n",
              "       metric_params=None, min_samples=5, n_jobs=None, p=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRSH-wPSF1Cl",
        "outputId": "916bb32b-070f-490c-b762-65f9dbeee029"
      },
      "source": [
        "silhouette_score(df2, db.labels_) #assesing model results\n",
        "db3.fit(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8156911152768872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(algorithm='auto', eps=0.1, leaf_size=30, metric='euclidean',\n",
              "       metric_params=None, min_samples=5, n_jobs=None, p=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IZOJNuiIF1IJ",
        "outputId": "1d1600cc-0dae-4799-e44c-521d2bb63e69"
      },
      "source": [
        "#Assessing the optimum hyperparamaters \n",
        "silhouettes = {}\n",
        "\n",
        "epss = np.arange(0.1, 0.9, 0.1)\n",
        "minss = [3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "ss = np.zeros((len(epss), len(minss)))\n",
        "\n",
        "for i, eps in enumerate(epss):\n",
        "    for j, mins in enumerate(minss):\n",
        "        db = DBSCAN(eps=eps, min_samples=mins).fit(df2)\n",
        "        if len(set(db.labels_)) == 1:\n",
        "            ss[i, j] = -1\n",
        "        else:\n",
        "            ss[i, j] = silhouette_score(df2, db.labels_, metric='euclidean')\n",
        "    \n",
        "\n",
        "plt.figure();\n",
        "#plt.plot(list(silhouettes.keys()), list(silhouettes.values()));\n",
        "for i in range(len(minss)):\n",
        "    plt.plot(epss, ss[:, i], label=\"MinPts = {}\".format(minss[i]));\n",
        "#plt.plot(epss, ss[:, 1]);\n",
        "plt.title('DBSCAN, Elbow Method')\n",
        "plt.xlabel(\"Eps\");\n",
        "plt.ylabel(\"Silhouette\");\n",
        "plt.legend();\n",
        "#plt.savefig('out/simple_dbscan_elbow');\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjhy378HNfvE"
      },
      "source": [
        "##### The optimal hyperparamter  an EPS of 0.1 to 0.4 and MinPts of 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ySJIgNr1Sfy"
      },
      "source": [
        "## 1.3 Model Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwQembOT1L6U"
      },
      "source": [
        "The DBSCAN outperforms the RF at the optimal hyperparameters as it has a higher mean score of 0.8156 as opposed to RF which has a mean score of 0.8004. This means that the DBSCAN is able to create clusters which are more differentiated, making it the better option but not significantly as the mean score difference is about 0.0152. In terms of speed, both models had a similar processing time, and one did not outperform the other so there wasn't really a significant advantage of one over the other. For interpretability, I opted to use the RF model as I found it easier to create personas out of its clusters. It might not necessarily be the case for all users, so I would say the ease at which one can interpret the clusters is relative. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP2EAnCJ1Xta"
      },
      "source": [
        "## 1.4 Personas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVewu2TZ1XhK"
      },
      "source": [
        "####**Cluster 1**- Retired Low spenders\n",
        "\n",
        "This cluster is made up of people in their 80's who are most likely dependent on their retirement package, hence the low income and high savings. They also tend to not spend a lot of money.\n",
        "\n",
        "####**Cluster 2-** Moderate Middle Agers\n",
        "\n",
        "This cluster is made up of people in their mid fifties to early sixties who are decent earners, have moderate to high income, moderate savings and moderate to high spending.\n",
        "\n",
        "#### **Cluster 3** - Responsible 30's\n",
        "\n",
        "This cluster is made up of people in their 30's who are very high earners, spend very little and save a lot.\n",
        "\n",
        "#### **Cluster 4** - Make Money, Spend Money, Save Money\n",
        "\n",
        "This cluster is made up of all ages, ranging from teenagers to people in their early nineties. It is the highest earning cluster of the bunch and has very little spending for those who are 30 and younger and very high spending for those abover 30 years old. The savings pattern in this cluster follows a similar pattern to spending. Those who are 30 and younger tend to save very little while those older than 30 tend to save quite a lot. I think this cluster can be broken down further into 30 and below and 30 and above as they have differentiated mutual traits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxIu4ZadMWFp",
        "outputId": "50db15b4-5aa7-422a-d118-33d2d3794cfa"
      },
      "source": [
        "k_means = KMeans(n_clusters=5, random_state=42) #recreating model with the optimal number of clusters for interpretation\n",
        "k_means.fit(df5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=42, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JlExaX0MkIQ",
        "outputId": "3939af8f-5b36-437b-f897-6d67fd23ae13"
      },
      "source": [
        "for label in set(k_means.labels_):\n",
        "    print('\\nCluster {}:'.format(label))\n",
        "    print(df5[k_means.labels_==label].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Cluster 0:\n",
            "    Age  Income  SpendingScore       Savings\n",
            "10   85  111389       0.036795  16009.237763\n",
            "13   31  107963       0.290509  13407.081391\n",
            "19   88  120678       0.063273  14264.473847\n",
            "24   89  119697       0.091679  16215.399077\n",
            "39   31  111449       0.294106  13929.621551\n",
            "\n",
            "Cluster 1:\n",
            "    Age  Income  SpendingScore       Savings\n",
            "4    87   17760       0.348778  16869.507130\n",
            "7    87   42592       0.355290  18086.287158\n",
            "8    83   34384       0.324719  14783.379086\n",
            "9    84   27693       0.367063  17879.558906\n",
            "17   87   31481       0.317424  16180.688082\n",
            "\n",
            "Cluster 2:\n",
            "   Age  Income  SpendingScore      Savings\n",
            "0   58   77769       0.791329  6559.829923\n",
            "1   59   81799       0.791082  5417.661426\n",
            "2   62   74751       0.702657  9258.992965\n",
            "3   59   74373       0.765680  7346.334504\n",
            "6   54   76500       0.785198  6878.884249\n",
            "\n",
            "Cluster 3:\n",
            "    Age  Income  SpendingScore       Savings\n",
            "11   36   99780       0.265433  16398.401333\n",
            "12   30   99949       0.344679  13621.639726\n",
            "20   30  101073       0.314387  14324.555977\n",
            "34   33  101058       0.315082  14911.868398\n",
            "38   39  100540       0.384923  16741.013895\n",
            "\n",
            "Cluster 4:\n",
            "    Age  Income  SpendingScore       Savings\n",
            "5    29  131578       0.847034   3535.514352\n",
            "15   92  122879       0.060724  13709.670275\n",
            "21   84  122696       0.082187  13809.734087\n",
            "25   30  122788       0.872872   5706.149573\n",
            "26   17  134966       0.907242   4128.044796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYwuYIgczYSv"
      },
      "source": [
        "# Question 2: Uncle Steve's Fine Foods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oCr-mTfNG-H"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "Uncle Steve runs a small, local grocery store in Ontario. The store sells all the normal food staples (e.g., bread, milk, cheese, eggs, more cheese, fruits, vegatables, meat, fish, waffles, ice cream, pasta, cereals, drinks), personal care products (e.g., toothpaste, shampoo, hair goo), medicine, and cakes. There's even a little section with flowers and greeting cards! Normal people shop here, and buy normal things in the normal way.\n",
        "\n",
        "Business is OK but Uncle Steve wants more. He's thus on the hunt for customer insights. Given your success at the jewelry store, he has asked you to help him out. \n",
        "\n",
        "He has given you a few years' worth of customer transactions, i.e., sets of items that customers have purchased. You have applied an association rules learning algorithm (like Apriori) to the data, and the algorithm has generated a large set of association rules of the form `{X} -> {Y}`, where `{X}` and `{Y}` are item-sets.\n",
        "\n",
        "Now comes a thought experiment. For each of the following scenarios, state what one of the discovered association rules might be that would meet the stated condition. (Just make up the rule, using your human experience and intuition.) Also, describe whether and why each rule would be considered interesting or uninteresting for Uncle Steve (i.e., is this insight new to him? Would he be able to use it somehow?).\n",
        "\n",
        "Keep each answer to 600 characters or less (including spaces).\n",
        "\n",
        "To get those brain juices going, an example condition and answer is provided below:\n",
        "\n",
        "> Condition: A rule that has high support.\n",
        "\n",
        "> Answer: The rule `{milk} -> {bread}` would have high support, since milk and bread are household staples and a high percentage of transactions would include both `{milk}` and `{bread}`. Uncle Steve would likely not find this rule interesting, because these items are so common, he would have surely already noticed that so many transactions contain them.\n",
        "\n",
        "**Marking**\n",
        "\n",
        "Your responses will be marked as follows:\n",
        "\n",
        "- *Correctness*. Rule meets the specificed condition, and seems plausible in an Ontario grocery store.\n",
        "- *Justification of interestness*. Response clearly describes whether and why the rule would be considered interesting to Uncle Steve.\n",
        "\n",
        "**Tips**\n",
        "\n",
        "- There is no actual data for this question. This question is just a thought exercise. You need to use your intuition, creatitivty, and understanding of the real world. I assume you are familiar with what happens inside of normal grocery stores. We are not using actual data and you do not need to create/generate/find any data. I repeat: there is no data for this question.\n",
        "- The reason this question is having you do a thought experiment, rather than writing and running code to find actual association rules on an actual dataset, is because writing code to find association rules is actually pretty easy. But using your brain to come up with rules that meet certain criteria, on the other hand, is a true test of whether you understand how the algorithm works, what support and confidence mean, and the applicability of rules. The question uses the grocery store context because most, if not all, students should be familiar from personal experience.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YQsOb6CzYVq"
      },
      "source": [
        "## 2.1: A rule that might have high support and high confidence. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzXu1IvK-MEg"
      },
      "source": [
        "{Cake} -> {Balloons}\n",
        " \n",
        " In most Ontario grocery stores it is quite common to see a cake purchased alongside other celebratory items such as balloons. Nonetheless,  cakes tend to be in the bakery section while balloons are at a different section of the store, right next to the flowers, celebratory cards etc. Since both goods are complimentary, it might be more beneficial to have them displayed within the same area or at least within a similar eye view range. That way, Uncle Steve can increase the chances of both complimentary goods being bought at the same time by customers who might have just intended to make a single purchase of both items. For instance, a customer might have come to the store to purchase a birthday cake and if they saw balloons right next to the cake, they may be incentivized to buy balloons as well to compliment the cake. Those items tend to go well together, especially for celebratory purposes. Ultimately, having complimentary products side by side can increase cross selling and overall product sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIrAgJk-L4l"
      },
      "source": [
        "## 2.2: A rule that might have reasonably high support but low confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svdzYW3S-LvF"
      },
      "source": [
        "{Canned Food} -> {Can Opener}\n",
        "\n",
        "Canned food are staple household items, depending on what time of food you consume.  On average these items tend to be opened with can openers and as a result, it is not uncommon to see both items in the same basket. Nonetheless, canned foods do not necessarily increase the likelihood of buying a can opener with every purchase of canned foods. This is because can openers are items that people purchase sparingly. People tend to purchase can openers only when their current can opener is broken or worn out. This is a key insight for Uncle Steve in terms of product placement and display space usage. Given that can openers are not products that are purchased very often, I would recommend that Uncle Steve does not provide a lot of shelf space for it. I would recommend that he places these items close to the canned foods, in terms of the display but with less shelf space so that he can have space for other products that need it more. Uncle Steve can economize the shelf space by hanging the can openers across the canned foods shelf. This layout also makes it accessible for his customers to purchase the products that they need with ease."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loe--LMz-Ll8"
      },
      "source": [
        "## 2.3: A rule that might have low support and low confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdyOB5fe-Zgy"
      },
      "source": [
        "{Regular Coke} -> {Diet Coke}\n",
        "\n",
        "\n",
        "People tend to be either diet coke or regular coke drinkers. It is odd to see and individual purchasing both items unless it’s for people other than themselves. But for this example, let’s assume that it’s based on a specific individuals purchase. A purchase of coke will unlikely increase the purchase of diet coke as individuals will have a strong preference between both items. This is important for Uncle Steve to know because its plausible for him to treat both items as substitutes. That is to say that he may think that if coke is out of stock, his customers might easily replace it with diet coke but that will most likely not be the case due to their strong preference per each item. The absence of coke will most likely result in an overall non purchase which will be lost sales for Uncle Steve had he had both items readily available. Therefore, Uncle Steve needs to treat both items as individuals and not substitutes and ensure that they are always stocked so his customers are able to purchase their preferred option which will translate to regular sales for him.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St2eI3We-ZYs"
      },
      "source": [
        "## 2.4: A rule that might have low support and high confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcdZc-B1-fE7"
      },
      "source": [
        "{Vegetable Platter} -> {Red Solo Cup}\n",
        "\n",
        "Right off the bat this seems like an odd combo, and it is not very common to see vegetables mixed with an item such as red solo cups. Veggie platters suggest relatively healthy eating, while red solo cups suggest college frat parties. Nonetheless, both items are products that one could easily spot at casual parties. Casual parties or get togethers tend to include plastic cups, plates etc. In my experience, there are almost always veggie options available for vegetarians and “healthy eaters” at these events, and veggie platters are they go-to due to the variety it offers. As a result, the purchase of a veggie platter can increase the likelihood of the purchase of a red solo cup. This is important for Uncle Steve to know in terms of product placement and cross-selling and up-selling. I would suggest that Uncle Steve places red solo cups relatively close to the veggie platter section, perhaps on a mini stand to encourage potential buyers who are purchasing veggie platters to pick up red solo cups as well. This will ultimately translate into more sales and better customer experience as their products of interest are within close range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_IHoz7f2yIV"
      },
      "source": [
        "# Question 3: Uncle Steve's Credit Union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhERdkp_zYBY"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "Uncle Steve has recently opened a new credit union in Kingston, named *Uncle Steve's Credit Union*. He plans to disrupt the local market by instaneously providing credit to customers.\n",
        "\n",
        "The first step in Uncle Steve's master plan is to create a model to predict whether an application has *good risk* or *bad risk*. He has outsourced the creation of this model to you.\n",
        "\n",
        "You are to create a classification model to predict whether a loan applicant has good risk or bad risk. You will use data  that Uncle Steve bought from another credit union (somewhere in Europe, he thinks?) that has around 6000 instances and a number of demographics features (e.g., `Sex`, `DateOfBirth`, `Married`), loan details (e.g., `Amount`, `Purpose`), credit history (e.g., number of loans), as well as an indicator (called `BadCredit` in the dataset) as to whether that person was a bad risk.\n",
        "\n",
        "\n",
        "**Your tasks**\n",
        "\n",
        "To examine the effects of the various ML stages, you are to create the model several times, each time adding more sophistication, and measuring how much the model improved (or not). In particular, you will:\n",
        "\n",
        "0. Split the data in training and testing. Don't touch the testing data again, for any reason, until step 5. We are pretending that the testing data is \"future, unseen data that our model won't see until production.\" I'm serious, don't touch it. I'm watching you!\n",
        "1. Build a baseline model - no feature engineering, no feature selection, no hyperparameter tuning (just use the default settings), nothing fancy. (You may need to do some basic feature transformations, e.g., encoding of categorical features, or dropping of features you do not think will help or do not want to deal with yet.) Measure the performance using K-fold cross validation (recommended: [`sklearn.model_selection.cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)) on the training data. Use at least 5 folds, but more are better. Choose a [`scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) (i.e., classification metric) that you feel is appropriate for this task. Don't use accuracy. Print the mean score of your model.\n",
        "2. Add a bit of feature engineering. The [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module contains many useful transformations. Engineer at least three new features. They don't need to be especially ground-breaking or complicated. Dimensionality reduction techniques like [`sklearn.decomposition.PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) are fair game but not required. (If you do use dimensionality reduction techniques, it would only count as \"one\" new feature for the purposes of this assignment, even though I realize that PCA creates many new \"features\" (i.e., principal componentns).) Re-train your baseline model. Measure performance. Compare to step 1.\n",
        "3. Add feature selection. The [`sklearn.feature_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) has some algorithms for you to choose from. After selecting features, re-train your model, measure performance, and compare to step 2.\n",
        "4. Add hyperparameter tuning. Make reasonable choices and try to find the best (or at least, better) hyperparameters for your estimator and/or transformers. It's probably a good idea to stop using `cross_val_score` at this point and start using [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) as it is specifically built for this purpose and is more convienient to use. Measure performance and compare to step 3.\n",
        "5. Finally, estimate how well your model will work in production. Use the testing data (our \"future, unseen data\") from step 0. Transform the data as appropriate (easy if you've built a pipeline, a little more difficult if not), use the model from step 4 to get predictions, and measure the performance. How well did we do? \n",
        "\n",
        "\n",
        "**Marking**\n",
        "\n",
        "Each part will be marked for:\n",
        "- *Correctness*. Code clearly and fully performs the task specified.\n",
        "- *Reproducibility*. Code is fully reproducible. I.e., you (and I) should be able to run this Notebook again and again, from top to bottom, and get the same results each and every time.\n",
        "- *Style*. Code is organized. All parts commented with clear reasoning and rationale. No old code laying around. Code easy to follow. \n",
        "\n",
        "\n",
        "**Tips**\n",
        "- The origins of the dataset are a bit of a mystery. Assume the data set is recent (circa 2021) and up-to-date. Assume that column names are correct and accurate.\n",
        "- You don't need to experiment with more than one algorithm/estimator. Just choose one (e.g., [`sklearn.tree.DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), [`sklearn.ensemble.RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier), [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression), [`sklearn.svm.LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC), whatever) and stick with it for this question. \n",
        "- There is no minimum accuracy/precision/recall for this question. I.e., your mark will not be based on how good your model is. Rather, you mark will be based on good your process is.\n",
        "- Watch out for data leakage and overfitting. In particular, be sure to `fit()` any estimators and transformers (collectively, *objects*) only to the training data, and then use the objects' `transform()` methods on both the training and testing data. [Data School](https://www.youtube.com/c/dataschool/featured) has a [helpful video](https://www.youtube.com/watch?v=g2XsZdwbCCs) about this. [Pipelines](https://www.youtube.com/watch?v=1Y6O9nCo0-I) are very helpful here and make your code shorter and more robust (at the expense of making it harder to understand), and I recommend using them, but they are not required for this assignment.\n",
        "- Create as many code cells as you need. In general, each cell should do one \"thing.\"\n",
        "-\tDon't print large volumes of output. E.g., don't do: `df.head(100)`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqm_REd4oouz"
      },
      "source": [
        "## 3.0: Load data and split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6b_BM0Nz9sF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a4d0e1-ad63-4800-ede1-6253e565ae16"
      },
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "# First, we'll read the provided labeled training data\n",
        "df3 = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1wOhyCnvGeY4jplxI8lZ-bbYN3zLtickf\")\n",
        "df3.info()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df3.drop('BadCredit', axis=1) #.select_dtypes(['number'])\n",
        "y = df3['BadCredit']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000 entries, 0 to 5999\n",
            "Data columns (total 17 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   UserID             6000 non-null   object\n",
            " 1   Sex                6000 non-null   object\n",
            " 2   PreviousDefault    6000 non-null   int64 \n",
            " 3   FirstName          6000 non-null   object\n",
            " 4   LastName           6000 non-null   object\n",
            " 5   NumberPets         6000 non-null   int64 \n",
            " 6   PreviousAccounts   6000 non-null   int64 \n",
            " 7   ResidenceDuration  6000 non-null   int64 \n",
            " 8   Street             6000 non-null   object\n",
            " 9   LicensePlate       6000 non-null   object\n",
            " 10  BadCredit          6000 non-null   int64 \n",
            " 11  Amount             6000 non-null   int64 \n",
            " 12  Married            6000 non-null   int64 \n",
            " 13  Duration           6000 non-null   int64 \n",
            " 14  City               6000 non-null   object\n",
            " 15  Purpose            6000 non-null   object\n",
            " 16  DateOfBirth        6000 non-null   object\n",
            "dtypes: int64(8), object(9)\n",
            "memory usage: 797.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S8cr4ZkSsCZ",
        "outputId": "0a9cd9ef-c8db-45a1-e0d9-52030ede0be0"
      },
      "source": [
        "X.info() #Reviewing Data "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000 entries, 0 to 5999\n",
            "Data columns (total 16 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   UserID             6000 non-null   object\n",
            " 1   Sex                6000 non-null   object\n",
            " 2   PreviousDefault    6000 non-null   int64 \n",
            " 3   FirstName          6000 non-null   object\n",
            " 4   LastName           6000 non-null   object\n",
            " 5   NumberPets         6000 non-null   int64 \n",
            " 6   PreviousAccounts   6000 non-null   int64 \n",
            " 7   ResidenceDuration  6000 non-null   int64 \n",
            " 8   Street             6000 non-null   object\n",
            " 9   LicensePlate       6000 non-null   object\n",
            " 10  Amount             6000 non-null   int64 \n",
            " 11  Married            6000 non-null   int64 \n",
            " 12  Duration           6000 non-null   int64 \n",
            " 13  City               6000 non-null   object\n",
            " 14  Purpose            6000 non-null   object\n",
            " 15  DateOfBirth        6000 non-null   object\n",
            "dtypes: int64(7), object(9)\n",
            "memory usage: 750.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "BEsCGaTCU6wY",
        "outputId": "fc3903c2-689f-4779-a5da-1f6aac93bc0f"
      },
      "source": [
        "X.head(5) #Reviewing features more closely"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>Sex</th>\n",
              "      <th>PreviousDefault</th>\n",
              "      <th>FirstName</th>\n",
              "      <th>LastName</th>\n",
              "      <th>NumberPets</th>\n",
              "      <th>PreviousAccounts</th>\n",
              "      <th>ResidenceDuration</th>\n",
              "      <th>Street</th>\n",
              "      <th>LicensePlate</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Married</th>\n",
              "      <th>Duration</th>\n",
              "      <th>City</th>\n",
              "      <th>Purpose</th>\n",
              "      <th>DateOfBirth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>218-84-8180</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>Debra</td>\n",
              "      <td>Schaefer</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>503 Linda Locks</td>\n",
              "      <td>395C</td>\n",
              "      <td>3907</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>Port Keith</td>\n",
              "      <td>Vacation</td>\n",
              "      <td>1964-04-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>395-49-9764</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>Derek</td>\n",
              "      <td>Wright</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>969 Cox Dam Suite 101</td>\n",
              "      <td>UFZ 691</td>\n",
              "      <td>3235</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>Lake Debra</td>\n",
              "      <td>NewCar</td>\n",
              "      <td>1978-06-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>892-81-4890</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>Shannon</td>\n",
              "      <td>Smith</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>845 Kelly Estate</td>\n",
              "      <td>48A•281</td>\n",
              "      <td>3108</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>North Judithbury</td>\n",
              "      <td>NewCar</td>\n",
              "      <td>1972-03-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>081-11-7963</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>Christina</td>\n",
              "      <td>Brooks</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>809 Burns Creek</td>\n",
              "      <td>30Z J39</td>\n",
              "      <td>4014</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>Lake Chad</td>\n",
              "      <td>Other</td>\n",
              "      <td>1985-02-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>347-03-9639</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>Ralph</td>\n",
              "      <td>Anderson</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>248 Brandt Plains Apt. 465</td>\n",
              "      <td>71-Q331</td>\n",
              "      <td>3823</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>North Judithbury</td>\n",
              "      <td>Vacation</td>\n",
              "      <td>1983-08-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        UserID Sex  PreviousDefault  ...              City   Purpose  DateOfBirth\n",
              "0  218-84-8180   F                0  ...        Port Keith  Vacation   1964-04-07\n",
              "1  395-49-9764   M                0  ...        Lake Debra    NewCar   1978-06-02\n",
              "2  892-81-4890   F                0  ...  North Judithbury    NewCar   1972-03-18\n",
              "3  081-11-7963   F                0  ...         Lake Chad     Other   1985-02-26\n",
              "4  347-03-9639   M                0  ...  North Judithbury  Vacation   1983-08-08\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZhN_eHcZ5qQ",
        "outputId": "5da90671-88fb-4a10-bd8e-9ea489d3996d"
      },
      "source": [
        "X.select_dtypes([\"object\"]).nunique() #exploring the categorical features with unique values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UserID          6000\n",
              "Sex                2\n",
              "FirstName        600\n",
              "LastName         942\n",
              "Street          6000\n",
              "LicensePlate    5999\n",
              "City              20\n",
              "Purpose            8\n",
              "DateOfBirth     4215\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdiKKblCo53S"
      },
      "source": [
        "## 3.1: Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSumAZUAo9O6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b395a8da-3f8a-4d62-ef97-41e77b734ec0"
      },
      "source": [
        "#Pipline 1\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "numeric_features = ['Amount', 'Duration', 'NumberPets', \n",
        "                    'ResidenceDuration', 'Married', 'PreviousAccounts','PreviousDefault']\n",
        "\n",
        "categorical_features = ['City', 'Sex','Purpose']\n",
        "\n",
        "drop_features = ['UserID', 'DateOfBirth', 'FirstName', \"LastName\", \n",
        "                 'Street', 'LicensePlate']\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer()),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "      ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
        "      ])\n",
        "\n",
        "preprocessor1 = Pipeline(steps=[\n",
        "      ('ct', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features),\n",
        "            ('drop', 'drop', drop_features)],\n",
        "            remainder = 'passthrough', \n",
        "            sparse_threshold=0)),\n",
        "    ])\n",
        "\n",
        "pipe1 = Pipeline(steps=[('preprocessor', preprocessor1),  ('clf', clf)])\n",
        "\n",
        "scores1 = cross_val_score(pipe1, X_train, y_train, \n",
        "                          scoring='f1_macro', cv=10, n_jobs=-1)\n",
        "print(scores1)\n",
        "print(np.mean(scores1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.60335261 0.62309891 0.5425     0.65969125 0.62710811 0.6373402\n",
            " 0.56868105 0.62982277 0.61399851 0.59607293]\n",
            "0.6101666347932755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugyTS51Ko5vz"
      },
      "source": [
        "## 3.2: Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "742aYkYbprVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc65ba81-84ee-4925-9b29-9df1e394cadc"
      },
      "source": [
        "#Pipleline 2\n",
        "from sklearn.tree  import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import KernelPCA, PCA, TruncatedSVD\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "numeric_features = ['Amount', 'Duration', 'NumberPets', \n",
        "                    'ResidenceDuration', 'Married', 'PreviousAccounts','PreviousDefault']\n",
        "\n",
        "categorical_features = ['City', 'Sex','Purpose']\n",
        "\n",
        "drop_features = ['UserID', 'FirstName', \"LastName\", \n",
        "                 'Street', 'LicensePlate']\n",
        "\n",
        "def get_age_years(feature):\n",
        "  res = np.array([])\n",
        "  for instance in feature:\n",
        "    age = 2021 - int(instance[0:4])\n",
        "    res = np.append(res, age)\n",
        "  return res.reshape(-1, 1)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer()),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "      ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
        "      ])\n",
        "\n",
        "preprocessor2 = Pipeline(steps=[\n",
        "      ('ct', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('amount_log', FunctionTransformer(np.log10, validate=False), ['Amount']),\n",
        "            ('cat', categorical_transformer, categorical_features),\n",
        "            ('age', FunctionTransformer(get_age_years, validate=False), 'DateOfBirth'),\n",
        "            ('drop', 'drop', drop_features)],\n",
        "            remainder = 'passthrough', \n",
        "            sparse_threshold=0)),\n",
        "    ('pca', PCA(n_components=10)),\n",
        "    ])\n",
        "\n",
        "pipe2 = Pipeline(steps=[('preprocessor', preprocessor2),  ('clf', clf)])\n",
        "\n",
        "scores2 = cross_val_score(pipe2, X_train, y_train, \n",
        "                          scoring='f1_macro', cv=10, n_jobs=-1)\n",
        "print(scores2)\n",
        "print(np.mean(scores2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.75592531 0.76345083 0.71366221 0.715      0.73526167 0.69160235\n",
            " 0.76013516 0.72624375 0.67917973 0.72345679]\n",
            "0.7263917812460762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsdD0clko5pz"
      },
      "source": [
        "## 3.3: Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxX2ERqzpqxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a282d700-11d6-43bf-e688-441416922d29"
      },
      "source": [
        "#pipline 3\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.decomposition import KernelPCA, PCA, TruncatedSVD\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "numeric_features = ['Amount', 'Duration', 'NumberPets', \n",
        "                    'ResidenceDuration', 'Married', 'PreviousAccounts','PreviousDefault']\n",
        "\n",
        "categorical_features = ['City', 'Sex','Purpose']\n",
        "\n",
        "drop_features = ['UserID', 'FirstName', \"LastName\", \n",
        "                 'Street', 'LicensePlate']\n",
        "\n",
        "def get_age_years(feature):\n",
        "  res = np.array([])\n",
        "  for instance in feature:\n",
        "    age = 2021 - int(instance[0:4])\n",
        "    res = np.append(res, age)\n",
        "  return res.reshape(-1, 1)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer()),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "      ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
        "      ])\n",
        "\n",
        "preprocessor3 = Pipeline(steps=[\n",
        "      ('ct', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('amount_log', FunctionTransformer(np.log10, validate=False), ['Amount']),\n",
        "            ('cat', categorical_transformer, categorical_features),\n",
        "            ('age', FunctionTransformer(get_age_years, validate=False), 'DateOfBirth'),\n",
        "            ('drop', 'drop', drop_features)],\n",
        "            remainder = 'passthrough', \n",
        "            sparse_threshold=0)),\n",
        "    ('pca', PCA(n_components=11)),\n",
        "    ('feature_selector', SelectKBest(k=11))\n",
        "    ])\n",
        "\n",
        "pipe3 = Pipeline(steps=[('preprocessor', preprocessor3),  ('clf', clf)])\n",
        "\n",
        "scores3 = cross_val_score(pipe3, X_train, y_train, \n",
        "                          scoring='f1_macro', cv=11, n_jobs=-1)\n",
        "print(scores3)\n",
        "print(np.mean(scores3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.77267998 0.68704504 0.70162815 0.71154564 0.69964453 0.71658371\n",
            " 0.72675834 0.72398075 0.73429363 0.69674839 0.6971638 ]\n",
            "0.7152792715355275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff4l2aNKo5fr"
      },
      "source": [
        "## 3.4: Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XaxtTWMpIpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a99102-cd30-4681-a69d-95db3cb33c81"
      },
      "source": [
        "#Pipline 4\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "\n",
        "numeric_features = ['Amount', 'Duration', 'NumberPets', \n",
        "                    'ResidenceDuration', 'Married', 'PreviousAccounts','PreviousDefault']\n",
        "\n",
        "categorical_features = ['City', 'Sex','Purpose']\n",
        "\n",
        "drop_features = ['UserID', 'FirstName', \"LastName\", \n",
        "                 'Street', 'LicensePlate']\n",
        "\n",
        "\n",
        "def get_age_years(feature):\n",
        "  res = np.array([])\n",
        "  for instance in feature:\n",
        "    age = 2021 - int(instance[0:4])\n",
        "    res = np.append(res, age)\n",
        "  return res.reshape(-1, 1)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer()),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "      ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
        "      ])\n",
        "\n",
        "preprocessor4 = Pipeline(steps=[\n",
        "      ('ct', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('amount_log', FunctionTransformer(np.log10, validate=False), ['Amount']),\n",
        "            ('cat', categorical_transformer, categorical_features),\n",
        "            ('age', FunctionTransformer(get_age_years, validate=False), 'DateOfBirth'),\n",
        "            ('drop', 'drop', drop_features)],\n",
        "            remainder = 'passthrough', \n",
        "            sparse_threshold=0)),\n",
        "      ('feature_selector', SelectKBest(k=10)),\n",
        "    ])\n",
        "\n",
        "pipe4 = Pipeline(steps=[('preprocessor', preprocessor4),  ('clf', clf)])\n",
        "\n",
        "param_grid = {\n",
        "    'preprocessor__ct__num__scaler__with_mean': [True, False],\n",
        "    'preprocessor__ct__num__scaler__with_std': [True, False],\n",
        "    'preprocessor__feature_selector__k': [2,4,6,8,10],\n",
        "    'clf__max_depth': [None, 3, 5, 7, 9, 11, 13],\n",
        "    'clf__criterion': ['gini', 'entropy'], \n",
        "    'clf__class_weight':[None, 'balanced'],\n",
        "}\n",
        "\n",
        "pipe4 = GridSearchCV(pipe4, param_grid, cv=10, n_jobs=-1, \n",
        "                     scoring='f1_macro', return_train_score=True, verbose=2)\n",
        "\n",
        "pipe4 = pipe4.fit(X_train, y_train)\n",
        "\n",
        "print(pipe4.best_score_)\n",
        "print(pipe4.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 560 candidates, totalling 5600 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   18.4s\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:   40.9s\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=-1)]: Done 4897 tasks      | elapsed:  9.3min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7773262216708957\n",
            "{'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__max_depth': 5, 'preprocessor__ct__num__scaler__with_mean': True, 'preprocessor__ct__num__scaler__with_std': True, 'preprocessor__feature_selector__k': 2}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 5600 out of 5600 | elapsed: 10.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te9gGGLEpXRG"
      },
      "source": [
        "## 3.5: Performance estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV_35bEupbfs"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1gdEnGrxxK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e65217-447c-4800-ee3b-81033396cc1f"
      },
      "source": [
        "y_pred = pipe4.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[865 126]\n",
            " [ 37 172]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.87      0.91       991\n",
            "           1       0.58      0.82      0.68       209\n",
            "\n",
            "    accuracy                           0.86      1200\n",
            "   macro avg       0.77      0.85      0.80      1200\n",
            "weighted avg       0.89      0.86      0.87      1200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPiErnUaTQSk"
      },
      "source": [
        "# Question 4: Uncle Steve's Wind Farm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzLLQCmKTk9E"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "\n",
        "Uncle Steve has invested in wind. He's built a BIG wind farm with a total of  700 turbines. He's been running the farm for a couple of years now and things are going well. He sells the power generated by the farm to the Kingston government and makes a tidy profit. And, of course, he has been gathering data about the turbines' operations.\n",
        "\n",
        "One area of concern, however, is the cost of maintenece. While the turbines are fairly robust, it seems like one breaks/fails every couple of days. When a turbine fails, it usually costs around \\$20,000 to repair it. Yikes!\n",
        "\n",
        "Currently, Uncle Steve is not doing any preventative maintenance. He just waits until a turbine fails, and then he fixes it. But Uncle Steve has recently learned that if he services a turbine *before* it fails, it will only cost around $2,000. \n",
        "\n",
        "Obviously, there is a potential to save a lot of money here. But first, Uncle Steve would need to figure out *which* turbines are about to fail. Uncle Steve being Uncle Steve, he wants to use ML to build a predictive maintenance model. The model will alert Uncle Steve to potential turbine failures before they happen, giving Uncle Steve a chance to perform an inspection on the turbine and then fix the turbine before it fails. Uncle Steve plans to run the model every morning. For all the turbines that the model predicts will fail, Uncle Steve will order an inspection (which cost a flat \\$500, no matter if the turbine was in good health or not; the \\$500 would not be part of the $2,000 service cost). For the rest of the turbines, Uncle Steve will do nothing.\n",
        "\n",
        "Uncle Steve has used the last few year's worth of operation data to build and assess a model to predict which turbines will fail on any given day. (The data includes useful features like sensor readings, power output, weather, and many more, but those are not important for now.) In fact, he didn't stop there: he built and assessed two models. One model uses using deep learning (in this case, RNNs), and the other uses random forests.\n",
        "\n",
        "He's tuned the bejeebers out of each model and is comfortable that he has found the best-performing version of each. Both models seem really good: both have accuracy scores > 99%. The RNN has better recall, but Uncle Steve is convinced that the random forest model will be better for him since it has better precision. Just to be sure, he has hired you to double check his calculations. \n",
        "\n",
        "**Your task**\n",
        "\n",
        " Which model will save Uncle Steve more money? Justify.\n",
        "\n",
        "\n",
        "In addition to the details above, here is the assessment of each model:\n",
        "\n",
        "- Confusion matrix for the random forest:\n",
        "\n",
        "|         | Predicted Fail           | Predicted No Fail  |\n",
        "| ------------- |------------| -----:|\n",
        "| **Actual Fail**      | 201 | 55 |\n",
        "| **Actual No Fail**   | 50 | 255195 |\n",
        "\n",
        "- Confusion matrix for the RNN:\n",
        "\n",
        "|         | Predicted Fail           | Predicted No Fail  |\n",
        "| ------------- |------------| -----:|\n",
        "| **Actual Fail**      | 226 | 30 |\n",
        "| **Actual No Fail**   | 1200 | 254045 |\n",
        "\n",
        "\n",
        "**Marking**\n",
        "\n",
        "- *Quality*. Response is well-justified and convincing. \n",
        "- *Style*. Response uses proper grammar, spelling, and punctuation. Response is clear and professional. Response is complete, but not overly-verbose. Response follows length guidelines.\n",
        "\n",
        "\n",
        "\n",
        "**Tips**\n",
        "\n",
        "- Figure out how much Uncle Steve is currently (i.e., without any predictive maintinance models) paying in maintenance costs.\n",
        "- Use the information provided above to create a cost matrix.\n",
        "- Use the cost matrix and the confusion matrices to determine the costs of each model.\n",
        "- The cost of an inspection is the same, no matter if the turbine is in good condition or is about to fail.\n",
        "- If the inspection determines that a turbine is about to fail, then it will be fixed right then and there for the additional fee.\n",
        "- For simplicity, assume the inspections are perfect: i.e., that inspecting a turbine will definitely catch any problems that might exist, and won't accidentally flag an otherwise-healthy turbine.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC8iUGJsIYLj"
      },
      "source": [
        "## Answer\n",
        "\n",
        "Currently, Uncle Steve spends 14,000,000 dollars to fix all 700 turbines when they break or fail every few days. He has been exploring two varying ML models to predict which turbines will fail and treat those at a lesser preventative maintenance cost of 2500 dollars per turbine instead of the usual 20,000 per turbine. \n",
        "\n",
        "After completing the cost matrix for both models, the Random Forest will cost a total of 2,130,000 dollars while the RNN will cost 1,765,000 dollars. Based on the total sums from the cost matrix, the RNN seems more cost-effective. However, Uncle Steve believes Random Forest is the better option due to its higher precision of 80% compared to RNN with a precision of approximately 16%.\n",
        "\n",
        "In my opinion, Uncle Steve’s focus shouldn’t be on precision as it only assesses the percentage of yes predictions that were accurate. The consequence of predicting healthy turbines as unheathy is the flat fee inspection cost of 500 dollars per turbine. Uncle Steve’s focus should be on recall as it is more costly to him if his model inaccurately predicts turbines that will breakor fail in the next few days as healthy. The consequence of this is that these faulty turbines, which the ML model did not accurately predict, will result in inaction on Uncle Steve’s end. This inaction which will cost a total of 20,000 dollars per turbine in maintenance costs when the turbines eventually break down and need to be fixed.\n",
        "\n",
        "The RNN has a recall of 88% while Random Forest has a recall of 78%. As a result, RNN is the better model to deploy as it has a higher recall and will significantly reduce the overall maintenance costs due to its increased ability to predict the actual turbines that will break orfail in the next few days. This will allow for Uncle Steve to spend less money by relying more heavily on preventative maintenance in comparison to the higher maintenance cost he will be subjected to if he waits till after the turbines break.\n"
      ]
    }
  ]
}